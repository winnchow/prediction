data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
summary(mixtures$Superplasticizer)
hist(log(mixtures$Superplasticizer + 1))
library(mlbench)
install.packages("mlbench")
library(mlbench)
data("Glass")
str(Glass)
summary(Glass)
grep("Type", Glass)
grep("Type", names(Glass))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
summary(segmentationOriginal)
str(segmentationOriginal)
inTrain <- segmentationOriginal[Case == "Train"]
inTrain <- segmentationOriginal[Case = "Train"]
inTrain <- segmentationOriginal[segmentationOriginal$Case = "Train"]
inTrain <- segmentationOriginal[segmentationOriginal$Case == "Train"]
inTrain <- segmentationOriginal[, segmentationOriginal$Case == "Train"]
inTrain <- segmentationOriginal[, segmentationOriginal$Case = "Train"]
inTrain <- segmentationOriginal[, Case = "Train"]
inTrain <- segmentationOriginal[, Case = Train]
inTrain <- segmentationOriginal[,]
inTrain <- segmentationOriginal[, Case = 2]
inTrain <- segmentationOriginal[, Case == 2]
inTrain <- segmentationOriginal[, segmentationOriginal$Case == 2]
training <- segmentationOriginal[, segmentationOriginal$Case == 2]
training <- segmentationOriginal[, segmentationOriginal$Case == 2]
testing <- segmentationOriginal[, segmentationOriginal$Case == 1]
training <- segmentationOriginal[segmentationOriginal$Case == 2, ]
testing <- segmentationOriginal[segmentationOriginal$Case == 1, ]
summary(segmentationOriginal$Case)
summary(segmentationOriginal$Case = 1)
summary(segmentationOriginal$Case == 1)
summary(segmentationOriginal$Case == 2)
summary(segmentationOriginal$Case == "Test")
testing <- segmentationOriginal[segmentationOriginal$Case == "Test", ]
training <- segmentationOriginal[segmentationOriginal$Case == "Train", ]
set.seed(125)
modFit <- train(Class ~ ., method="rpart")
modFit <- train(Class ~ ., method="rpart", data=training)
modFit
modFit$finalModel
predit(modFit, newdata=testing)
predict(modFit, newdata=testing)
modFit$finalModel
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
summary(oliva)
summary(olive)
view(olive)
View(olive)
modFit <- train( ~ ., method="rpart", data=olive)
modFit <- train(Area ~ ., method="rpart", data=olive)
summary(is.na(olive))
predict(modFit, newdata=as.data.frame(t(colMeans(olive))))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(testSA)
modFit <- train(chd ~ age + alcohol + obesity + tabacco + typea + ldl, method="glm", data=trainSA, family="binomial")
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", data=trainSA, family="binomial")
p <- predict(modFit, newdata=testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, p)
t <- predict(modFit, newdata=trainSA)
missClass(trainSA$chd, t)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
View(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
summary(vowel.train)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modFit　<- train(y ~ ., data=vowel.train, method="rf", prox=TRUE)
modFit　<- train(y ~ ., data=vowel.train, method="rf", prox=TRUE)
varImp(modFit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
mod1 <- train(y ~ ., method="rf", data=vowel.train)
train()
library(caret)
train()
mod1 <- train(y ~ ., method="rf", data=vowel.train)
p1 <- predict(mod1, newdata = vowel.test)
p1
table(p1, vowel.test$y
)
confusionMatrix(p1, vowel.test$y)
mod1 <- train(y ~ ., method="rf", data=vowel.train, trControl = trainControl(method="cv"), number=3)
p1 <- predict(mod1, newdata = vowel.test)
confusionMatrix(p1, vowel.test$y)
mod2 <- train(y ~ ., method="gbm", data=vowel.train)
p2 <- predict(mod2, newdata = vowel.test)
confusionMatrix(p2, vowel.test$y)
p3 <- p1[p1 == p2]
y2 <- vowel.test$y[p1 == p2]
confusionMatrix(p3, y2)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(training)
mod1 <- train(diagnosis ~ ., method="rf", data=training)
mod2 <- train(diagnosis ~ ., method="gbm", data=training)
mod3 <- train(diagnosis ~ ., method="lda", data=training)
p1 <- predict(mod1, newdata = testing)
p2 <- predict(mod2, newdata = testing)
p3 <- predict(mod3, newdata = testing)
confusionMatrix(p1, testing$diagnosis)
confusionMatrix(p2, testing$diagnosis)
confusionMatrix(p3, testing$diagnosis)
predDF <- data.frame(p1, p2, p3, diagnosis=testing$diagnosis)
combModFit <- train(wage ~., method="rf", data=predDF)
combModFit <- train(diagnosis ~., method="rf", data=predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)
p1 <- predict(mod1, newdata = training)
p3 <- predict(mod3, newdata = training)
p2 <- predict(mod2, newdata = training)
predDF <- data.frame(p1, p2, p3, diagnosis=training$diagnosis)
combModFit <- train(diagnosis ~., method="rf", data=predDF)
p1 <- predict(mod1, newdata = testing)
p2 <- predict(mod2, newdata = testing)
p3 <- predict(mod3, newdata = testing)
predDF <- data.frame(p1, p2, p3, diagnosis=testing$diagnosis)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
modFit <- train(CompressiveStrength ~ ., method="lasso", data=training)
?plot.enet
plot.enet(modFit)
modFit
modFit$finalModel
plot.enet(modFit$finalModel)
?plot.enet
plot.enet(modFit$finalModel, xvar=step)
plot.enet(modFit$finalModel, xvar=c(step)
)
plot.enet(modFit$finalModel, xvar=c("step"))
modFit$finalModel$Cp
modFit$finalModel$vn
modFit$finalModel
modFit <- train(CompressiveStrength ~ ., method="lasso", newdata
p <- predict(modFit, newdata=testing)
p
p <- predict(modFit, newdata=testing, type=coefficients)
p <- predict(modFit, newdata=testing, type="coefficients")
p <- predict(modFit, newdata=testing)
modFit$finalModel
plot.enet(lasso.model$finalModel, xvar="penalty", use.color=TRUE)
plot.enet(modFit$finalModel, xvar="penalty", use.color=TRUE)
library(lubridate)
install.packages("lubridate")
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
getwd
getwd()
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
library(forecast)
?bats
forecast(bats(tstrain))
View(testing)
?forecast
forecast(bats(tstrain), h=600-366+1)
pf <- forecast(bats(tstrain), h=600-366+1)
summary(pf)
str(pf)
head(pf)
pf$upper
pf$level
pf <- forecast(bats(tstrain), h=600-366+1, level=95)
pf
pf$level
pf$lower
testing
View(tstrain)
600 - 366 +1
testing[testing$visitsTumblr >= pf$lower && testing$visitsTumblr <= pf$upper]
t <- testing[testing$visitsTumblr >= pf$lower && testing$visitsTumblr <= pf$upper]
dim(t)
testing$visitsTumblr >= pf$lower
pf$lower
pf$upper
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
install.packages("e1071")
set.seed(325)
View(training )
svm_model <- svm(CompressiveStrength ~ ., data = training)
library(e1071)
svm_model <- svm(CompressiveStrength ~ ., data = training)
pred <- predict(svm_model, testing)
pred
accuracy(pred, testing$CompressiveStrength)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(testing)
modFit1 <- train(diagnosis ~ ., method="rf", data = training)
modFit1 <- train(diagnosis ~ ., method="gbm", data = training)
modFit2 <- train(diagnosis ~ ., method="rf", data = training)
modFit3 <- train(diagnosis ~ ., method="lda", data = training)
p1 <- predict(modFit1, newdata = testing)
p2 <- predict(modFit2, newdata = testing)
p3 <- predict(modFit3, newdata = testing)
confusionMatrix(p1, testing$diagnosis)
confusionMatrix(p2, testing$diagnosis)
confusionMatrix(p3, testing$diagnosis)
combinedset <- data.frame(p1, p2, p3, diagnosis = testing$diagnosis)
fit <- train(diagnosis~., combinedset, method="rf")
predict <- predict(fit, testing)
cm <- confusionMatrix(predict, testing$diagnosis)
cmRF$overall['Accuracy']
cm$overall['Accuracy']
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
mod <- bats(tstrain)
fcast <- forecast.bats(mod, level=95, h=nrow(testing))
acc <- accuracy(fcast, testing$visitsTumblr)
count <- 0
for (i in 1:nrow(testing)) {
if (testing$visitsTumblr[i] > fcast$lower[i]) {
if(testing$visitsTumblr[i] < fcast$upper[i]) {
count <- count + 1}
}
}
count/nrow(testing)
mod <- bats(tstrain)
fcast <- forecast(mod, level=95, h=nrow(testing))
acc <- accuracy(fcast, testing$visitsTumblr)
acc
sum(testing$visitsTumblr[i] > fcast$lower[i])
count(testing$visitsTumblr[i] > fcast$lower[i])
sum(testing$visitsTumblr > fcast$lower)
count <- 0
for (i in 1:nrow(testing)) {
if (testing$visitsTumblr[i] > fcast$lower[i]) {
if(testing$visitsTumblr[i] < fcast$upper[i]) {
count <- count + 1}
}
}
count/nrow(testing)
sum(testing$visitsTumblr < fcast$upper)
sum(testing$visitsTumblr <= fcast$upper)
226/235
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
library(gbm)
library(mgcv)
library(nlme)
library(elasticnet)
prf <- predict(rf, vowel.test)
pgbm <- predict(gbm, vowel.test)
cmrf <- confusionMatrix(prf, vowel.test$y)
cmgbm <- confusionMatrix(pgbm, vowel.test$y)
cmrf$overall['Accuracy']
set.seed(33833)
View(vowel.train)
rf <- train(y ~ ., method="rf", data=vowel.test)
gbm <- train(y ~ ., method="gbm", data=vowel.test)
prf <- predict(rf, vowel.test)
pgbm <- predict(gbm, vowel.test)
cmrf <- confusionMatrix(prf, vowel.test$y)
cmgbm <- confusionMatrix(pgbm, vowel.test$y)
cmrf$overall['Accuracy']
nrow(prf)
prf <- predict(rf, vowel.test)
prf
nrow(prf)
confusionMatrix(prf, vowel.test$y)
rf <- train(y ~ ., method="rf", data=vowel.train)
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE, ntree = 10, allowParallel = TRUE)
library(caret)
library(rattle)
summary(training)
training <- read.csv(file="pml-training.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
setwd("C:\\Users\\user\\Documents\\GitHub\\prediction")
training <- read.csv(file="pml-training.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
testing <- read.csv(file="pml-testing.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
dv <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- training[, !(names(training) %in% dv)]
## Remove near zero variables
nzv <- nearZeroVar(training)
training <- training[, -nzv]
## Remove variables with more than 30% of NA
nas <- sapply(training, function(x) { sum(is.na(x)) <= 0.3 * length(training$classe) })
training <- training[, nas]
## 10-fold cross-validation
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE, ntree = 10, allowParallel = TRUE)
View(acc)
rm(ls())
rm(list=ls())
training <- read.csv(file="pml-training.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
testing <- read.csv(file="pml-testing.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
dv <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- training[, !(names(training) %in% dv)]
nzv <- nearZeroVar(training)
training <- training[, -nzv]
nas <- sapply(training, function(x) { sum(is.na(x)) <= 0.3 * length(training$classe) })
training <- training[, nas]
train <- createDataPartition(training$classe, p = 0.8, list = FALSE)
training <- training[train, ]
Validation <- training[-train, ]
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE, ntree = 10, allowParallel = TRUE)
warnings
warnings()
help(memory.size)
memory.limit()
memory.size()
memory.size()
?memory.size
memory.limit()
memory.limit(12148*2)
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE, ntree = 10, allowParallel = TRUE)
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE, ntree = 10, allowParallel = TRUE)
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE, allowParallel = TRUE)
train <- createDataPartition(training$classe, p = 0.1, list = FALSE)
training <- read.csv(file="pml-training.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
dv <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- training[, !(names(training) %in% dv)]
## Remove near zero variables
nzv <- nearZeroVar(training)
training <- training[, -nzv]
## Remove variables with more than 30% of NA
nas <- sapply(training, function(x) { sum(is.na(x)) <= 0.3 * length(training$classe) })
training <- training[, nas]
## Splitting data
## As the number of data is sufficiently large, the validation set approach is used
train <- createDataPartition(training$classe, p = 0.1, list = FALSE)
training <- training[train, ]
Validation <- training[-train, ]
training <- read.csv(file="pml-training.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
testing <- read.csv(file="pml-testing.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
dv <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- training[, !(names(training) %in% dv)]
## Remove near zero variables
nzv <- nearZeroVar(training)
training <- training[, -nzv]
## Remove variables with more than 30% of NA
nas <- sapply(training, function(x) { sum(is.na(x)) <= 0.3 * length(training$classe) })
training <- training[, nas]
## Splitting data
## As the number of data is sufficiently large, the validation set approach is used
train <- createDataPartition(training$classe, p = 0.1, list = FALSE)
trainingSet <- training[train, ]
ValidationSet <- training[-train, ]
## Training
## This is a classification problem
## Random forest is chosen to be the modelling method. Random forests are usually one
## of the top performing algorithms in prediction contests.
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, allowParallel = TRUE)
install.packages("rmarkdown")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
train <- createDataPartition(training$classe, p = 0.05, list = FALSE)
trainingSet <- training[train, ]
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, allowParallel = TRUE)
View(trainingSet)
summary(trainingSet)
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE)
modFit
modFit$results
pt <- predict(modFit, trainingSet)
confusionMatrix(pt, trainingSet$classe)
ValidationSet <- training[-train, ]
pt <- predict(modFit, ValidationSet)
confusionMatrix(pt, validationSet$classe)
confusionMatrix(pt, ValidationSet$classe)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
modFit$finalModel
train <- createDataPartition(training$classe, p = 0.7, list = FALSE)
trainingSet <- training[train, ]
ValidationSet <- training[-train, ]
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, allowParallel = TRUE)
train <- createDataPartition(training$classe, p = 0.2, list = FALSE)
trainingSet <- training[train, ]
ValidationSet <- training[-train, ]
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, allowParallel = TRUE)
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, ntree = 4, allowParallel = TRUE)
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, ntree = 4, allowParallel = TRUE)
p <- predict(modFit, trainingSet)
confusionMatrix(p, trainingSet$classe)
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, ntree = 10, allowParallel = TRUE)
p <- predict(modFit, trainingSet)
confusionMatrix(p, trainingSet$classe)
confusionMatrix(p, trainingSet$classe)
p <- predict(modFit, validationSet)
p <- predict(modFit, ValidationSet)
confusionMatrix(p, ValidationSet$classe)
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, ntree = 12, allowParallel = TRUE)
p <- predict(modFit, trainingSet)
confusionMatrix(p, trainingSet$classe)
p <- predict(modFit, ValidationSet)
confusionMatrix(p, ValidationSet$classe)
train <- createDataPartition(training$classe, p = 0.5, list = FALSE)
trainingSet <- training[train, ]
ValidationSet <- training[-train, ]
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, ntree = 12, allowParallel = TRUE)
p <- predict(modFit, trainingSet)
confusionMatrix(p, trainingSet$classe)
p <- predict(modFit, ValidationSet)
confusionMatrix(p, ValidationSet$classe)
train <- createDataPartition(training$classe, p = 0.7, list = FALSE)
trainingSet <- training[train, ]
ValidationSet <- training[-train, ]
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, ntree = 12, allowParallel = TRUE)
p <- predict(modFit, trainingSet)
confusionMatrix(p, trainingSet$classe)
p <- predict(modFit, ValidationSet)
confusionMatrix(p, ValidationSet$classe)
modFit <- train(classe ~ ., data = trainingSet, method = "rf", prox = TRUE, ntree = 16, allowParallel = TRUE)
p <- predict(modFit, trainingSet)
confusionMatrix(p, trainingSet$classe)
p <- predict(modFit, ValidationSet)
confusionMatrix(p, ValidationSet$classe)
p <- predict(modFit, testing)
confusionMatrix(p, testing$classe)
summary(testing)
View(testing)
p
p[2] <- 1:20
pm <- data.frame(p, 1:20)
pm
confusionMatrix(p, ValidationSet$classe)
p <- predict(modFit, ValidationSet)
confusionMatrix(p, ValidationSet$classe)
set.seed(111111)
rm(list=ls())
set.seed(123123123)
train <- createDataPartition(training$classe, p = 0.7, list = FALSE)
trainingSet <- training[train, ]
ValidationSet <- training[-train, ]
