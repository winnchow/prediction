install.packages("e1071")
modelFit <- train(training$diagnosis ~ ., method="glm", data=training)
modelFit <- train(training$diagnosis ~ ., method="glm", data=training)
modelFit <- train(diagnosis ~ ., method="glm", data=training)
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
modelFit2 <- train(diagnosis ~ ., method="glm", preProcess="pca", thresh=0.8, data=training)
modelFit2 <- train(diagnosis ~ ., method="glm", preProcess="pca", data=training)
ctrl <- trainControl(preProcOptions = list(thresh = 0.8))
modelFit2 <- train(diagnosis ~ ., method="glm", preProcess="pca", trControl=ctrl, data=training)
confusionMatrix(testing$diagnosis, predict(modelFit2, testing))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
require(Hmisc)
inds<-1:nrow(training)
# view step pattern in plot
q<-qplot(x = inds, y = CompressiveStrength, data = training); q
nameslist<-names(training)
cutall<-sapply(nameslist, function(nameslist){
cut2(training[[nameslist]], g=5)
})
cutall<-as.data.frame(cutall)
cutnames<-sapply(nameslist, function(nameslist){paste("cut", nameslist, sep="")})
colnames(cutall)<-cutnames
# plot the data coloured by the cuts in each of the variables
for(Var in names(cutall)) {
print(qplot(x = inds, y = CompressiveStrength, data=training, color=cutall[[Var]], main = Var))
}
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preProc <- preProcess(pred, method="pca", thresh=0.8)
preProc
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
summary(mixtures$Superplasticizer)
hist(log(mixtures$Superplasticizer + 1))
library(mlbench)
install.packages("mlbench")
library(mlbench)
data("Glass")
str(Glass)
summary(Glass)
grep("Type", Glass)
grep("Type", names(Glass))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
summary(segmentationOriginal)
str(segmentationOriginal)
inTrain <- segmentationOriginal[Case == "Train"]
inTrain <- segmentationOriginal[Case = "Train"]
inTrain <- segmentationOriginal[segmentationOriginal$Case = "Train"]
inTrain <- segmentationOriginal[segmentationOriginal$Case == "Train"]
inTrain <- segmentationOriginal[, segmentationOriginal$Case == "Train"]
inTrain <- segmentationOriginal[, segmentationOriginal$Case = "Train"]
inTrain <- segmentationOriginal[, Case = "Train"]
inTrain <- segmentationOriginal[, Case = Train]
inTrain <- segmentationOriginal[,]
inTrain <- segmentationOriginal[, Case = 2]
inTrain <- segmentationOriginal[, Case == 2]
inTrain <- segmentationOriginal[, segmentationOriginal$Case == 2]
training <- segmentationOriginal[, segmentationOriginal$Case == 2]
training <- segmentationOriginal[, segmentationOriginal$Case == 2]
testing <- segmentationOriginal[, segmentationOriginal$Case == 1]
training <- segmentationOriginal[segmentationOriginal$Case == 2, ]
testing <- segmentationOriginal[segmentationOriginal$Case == 1, ]
summary(segmentationOriginal$Case)
summary(segmentationOriginal$Case = 1)
summary(segmentationOriginal$Case == 1)
summary(segmentationOriginal$Case == 2)
summary(segmentationOriginal$Case == "Test")
testing <- segmentationOriginal[segmentationOriginal$Case == "Test", ]
training <- segmentationOriginal[segmentationOriginal$Case == "Train", ]
set.seed(125)
modFit <- train(Class ~ ., method="rpart")
modFit <- train(Class ~ ., method="rpart", data=training)
modFit
modFit$finalModel
predit(modFit, newdata=testing)
predict(modFit, newdata=testing)
modFit$finalModel
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
summary(oliva)
summary(olive)
view(olive)
View(olive)
modFit <- train( ~ ., method="rpart", data=olive)
modFit <- train(Area ~ ., method="rpart", data=olive)
summary(is.na(olive))
predict(modFit, newdata=as.data.frame(t(colMeans(olive))))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(testSA)
modFit <- train(chd ~ age + alcohol + obesity + tabacco + typea + ldl, method="glm", data=trainSA, family="binomial")
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", data=trainSA, family="binomial")
p <- predict(modFit, newdata=testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, p)
t <- predict(modFit, newdata=trainSA)
missClass(trainSA$chd, t)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
View(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
summary(vowel.train)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modFit　<- train(y ~ ., data=vowel.train, method="rf", prox=TRUE)
modFit　<- train(y ~ ., data=vowel.train, method="rf", prox=TRUE)
varImp(modFit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
mod1 <- train(y ~ ., method="rf", data=vowel.train)
train()
library(caret)
train()
mod1 <- train(y ~ ., method="rf", data=vowel.train)
p1 <- predict(mod1, newdata = vowel.test)
p1
table(p1, vowel.test$y
)
confusionMatrix(p1, vowel.test$y)
mod1 <- train(y ~ ., method="rf", data=vowel.train, trControl = trainControl(method="cv"), number=3)
p1 <- predict(mod1, newdata = vowel.test)
confusionMatrix(p1, vowel.test$y)
mod2 <- train(y ~ ., method="gbm", data=vowel.train)
p2 <- predict(mod2, newdata = vowel.test)
confusionMatrix(p2, vowel.test$y)
p3 <- p1[p1 == p2]
y2 <- vowel.test$y[p1 == p2]
confusionMatrix(p3, y2)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(training)
mod1 <- train(diagnosis ~ ., method="rf", data=training)
mod2 <- train(diagnosis ~ ., method="gbm", data=training)
mod3 <- train(diagnosis ~ ., method="lda", data=training)
p1 <- predict(mod1, newdata = testing)
p2 <- predict(mod2, newdata = testing)
p3 <- predict(mod3, newdata = testing)
confusionMatrix(p1, testing$diagnosis)
confusionMatrix(p2, testing$diagnosis)
confusionMatrix(p3, testing$diagnosis)
predDF <- data.frame(p1, p2, p3, diagnosis=testing$diagnosis)
combModFit <- train(wage ~., method="rf", data=predDF)
combModFit <- train(diagnosis ~., method="rf", data=predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)
p1 <- predict(mod1, newdata = training)
p3 <- predict(mod3, newdata = training)
p2 <- predict(mod2, newdata = training)
predDF <- data.frame(p1, p2, p3, diagnosis=training$diagnosis)
combModFit <- train(diagnosis ~., method="rf", data=predDF)
p1 <- predict(mod1, newdata = testing)
p2 <- predict(mod2, newdata = testing)
p3 <- predict(mod3, newdata = testing)
predDF <- data.frame(p1, p2, p3, diagnosis=testing$diagnosis)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
modFit <- train(CompressiveStrength ~ ., method="lasso", data=training)
?plot.enet
plot.enet(modFit)
modFit
modFit$finalModel
plot.enet(modFit$finalModel)
?plot.enet
plot.enet(modFit$finalModel, xvar=step)
plot.enet(modFit$finalModel, xvar=c(step)
)
plot.enet(modFit$finalModel, xvar=c("step"))
modFit$finalModel$Cp
modFit$finalModel$vn
modFit$finalModel
modFit <- train(CompressiveStrength ~ ., method="lasso", newdata
p <- predict(modFit, newdata=testing)
p
p <- predict(modFit, newdata=testing, type=coefficients)
p <- predict(modFit, newdata=testing, type="coefficients")
p <- predict(modFit, newdata=testing)
modFit$finalModel
plot.enet(lasso.model$finalModel, xvar="penalty", use.color=TRUE)
plot.enet(modFit$finalModel, xvar="penalty", use.color=TRUE)
library(lubridate)
install.packages("lubridate")
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
getwd
getwd()
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
library(forecast)
?bats
forecast(bats(tstrain))
View(testing)
?forecast
forecast(bats(tstrain), h=600-366+1)
pf <- forecast(bats(tstrain), h=600-366+1)
summary(pf)
str(pf)
head(pf)
pf$upper
pf$level
pf <- forecast(bats(tstrain), h=600-366+1, level=95)
pf
pf$level
pf$lower
testing
View(tstrain)
600 - 366 +1
testing[testing$visitsTumblr >= pf$lower && testing$visitsTumblr <= pf$upper]
t <- testing[testing$visitsTumblr >= pf$lower && testing$visitsTumblr <= pf$upper]
dim(t)
testing$visitsTumblr >= pf$lower
pf$lower
pf$upper
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
install.packages("e1071")
set.seed(325)
View(training )
svm_model <- svm(CompressiveStrength ~ ., data = training)
library(e1071)
svm_model <- svm(CompressiveStrength ~ ., data = training)
pred <- predict(svm_model, testing)
pred
accuracy(pred, testing$CompressiveStrength)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(testing)
modFit1 <- train(diagnosis ~ ., method="rf", data = training)
modFit1 <- train(diagnosis ~ ., method="gbm", data = training)
modFit2 <- train(diagnosis ~ ., method="rf", data = training)
modFit3 <- train(diagnosis ~ ., method="lda", data = training)
p1 <- predict(modFit1, newdata = testing)
p2 <- predict(modFit2, newdata = testing)
p3 <- predict(modFit3, newdata = testing)
confusionMatrix(p1, testing$diagnosis)
confusionMatrix(p2, testing$diagnosis)
confusionMatrix(p3, testing$diagnosis)
combinedset <- data.frame(p1, p2, p3, diagnosis = testing$diagnosis)
fit <- train(diagnosis~., combinedset, method="rf")
predict <- predict(fit, testing)
cm <- confusionMatrix(predict, testing$diagnosis)
cmRF$overall['Accuracy']
cm$overall['Accuracy']
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
mod <- bats(tstrain)
fcast <- forecast.bats(mod, level=95, h=nrow(testing))
acc <- accuracy(fcast, testing$visitsTumblr)
count <- 0
for (i in 1:nrow(testing)) {
if (testing$visitsTumblr[i] > fcast$lower[i]) {
if(testing$visitsTumblr[i] < fcast$upper[i]) {
count <- count + 1}
}
}
count/nrow(testing)
mod <- bats(tstrain)
fcast <- forecast(mod, level=95, h=nrow(testing))
acc <- accuracy(fcast, testing$visitsTumblr)
acc
sum(testing$visitsTumblr[i] > fcast$lower[i])
count(testing$visitsTumblr[i] > fcast$lower[i])
sum(testing$visitsTumblr > fcast$lower)
count <- 0
for (i in 1:nrow(testing)) {
if (testing$visitsTumblr[i] > fcast$lower[i]) {
if(testing$visitsTumblr[i] < fcast$upper[i]) {
count <- count + 1}
}
}
count/nrow(testing)
sum(testing$visitsTumblr < fcast$upper)
sum(testing$visitsTumblr <= fcast$upper)
226/235
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
library(gbm)
library(mgcv)
library(nlme)
library(elasticnet)
prf <- predict(rf, vowel.test)
pgbm <- predict(gbm, vowel.test)
cmrf <- confusionMatrix(prf, vowel.test$y)
cmgbm <- confusionMatrix(pgbm, vowel.test$y)
cmrf$overall['Accuracy']
set.seed(33833)
View(vowel.train)
rf <- train(y ~ ., method="rf", data=vowel.test)
gbm <- train(y ~ ., method="gbm", data=vowel.test)
prf <- predict(rf, vowel.test)
pgbm <- predict(gbm, vowel.test)
cmrf <- confusionMatrix(prf, vowel.test$y)
cmgbm <- confusionMatrix(pgbm, vowel.test$y)
cmrf$overall['Accuracy']
nrow(prf)
prf <- predict(rf, vowel.test)
prf
nrow(prf)
confusionMatrix(prf, vowel.test$y)
rf <- train(y ~ ., method="rf", data=vowel.train)
?read.csv
getwd()
cd
setwd("C:\Users\user\Documents\GitHub\prediction")
setwd("C:/Users/user/Documents/GitHub/prediction")
getwd()
ls
ls()
train <- read.csv(file="pml-training.csv", header=TRUE, na.strings = c("", "NA"))
View(train)
summary(train)
train <- read.csv(file="pml-training.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
summary(train)
dim(train)
testing <- read.csv(file="pml-testing.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
summary(testing)
dim(testing)
View(testing)
nrow(training)
dim(trianing)
dim(training
)
training <- read.csv(file="pml-training.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
dim(training
)
nrow(training)
ncolumn(training)
ncol(training)
hist(training$classe)
summary(training$classe)
barplot(training$classe)
training$classe
barplot(training$classe)
?barplot()
barplot(table(training$classe))
?barplot
barplot(table(training$classe, main = "classe"))
barplot(table(training$classe), main = "classe")
barplot(table(training$classe), main = "Classe")
?barplot
barplot(table(training$classe), main = "Classe", xlim = 5000)
barplot(table(training$classe), main = "Classe", ylim = 5000)
barplot(table(training$classe), main = "Classe", ylim = c(5000))
?barplot
barplot(table(training$classe), main = "Classe", ylim = c(0, 5000))
barplot(table(training$classe), main = "Classe", ylim = c(0, 6000))
createFolds?
?createFolds
flds <- createFolds(training, k = 10, list = TRUE, returnTrain = FALSE)
library(caret)
flds <- createFolds(training, k = 10, list = TRUE, returnTrain = FALSE)
summary(flds)
flds[[1]]
dim(training)
flds <- createFolds(training, k = 10, list = TRUE, returnTrain = FALSE)
str(flds)
training[Fold01,]
training[flds[[1]],]
flds <- createFolds(training$classe, k = 10, list = TRUE, returnTrain = FALSE)
summary(flds)
flds <- createFolds(training$classe, k = 10, list = TRUE, returnTrain = TRUE)
summary(flds)
flds <- createFolds(training$classe, k = 10, list = TRUE, returnTrain = TRUE)
summary(flds)
dim(training$classe)
length(training$classe)
tc=trainControl(method = "cv", number=10)
nsv <- nearZeroVar(training, saveMetrics = TRUE)
nsv
length(training$new_window)
head(training$new_window)
summary(training$new_window)
nsv
?nearZeroVar
nzv <- nearZeroVar(training)
training <- training[, -nzv]
summary(training)
dim(training)
summary(training)
dim(training)
nas <- sapply(training, function(x) { sum(is.na(x)) })
nas
nas <- sapply(training, function(x) { sum(is.na(x)) < 0.5 * length(training$classe) })
nas
0.5 * length(training$classe)
nas <- sapply(training, function(x) { sum(is.na(x)) <= 0.3 * length(training$classe) })
nas
training <- training[, nas]
summary(training)
str(training)
View(training)
names(training)
training <- read.csv(file="pml-training.csv", header=TRUE, na.strings = c("", "NA", "#DIV/0!"))
names(training)
View(training)
summary(training$new_window)
training <- training[, !names(training) %in% dv]
training <- training[, !(names(training) %in% dv)]
dv
dv <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- training[, !(names(training) %in% dv)]
names(training)
View(training)
## Remove zero covariates
nzv <- nearZeroVar(training)
training <- training[, -nzv]
## Remove variables with more than 30% of NA
nas <- sapply(training, function(x) { sum(is.na(x)) <= 0.3 * length(training$classe) })
training <- training[, nas]
summary(training)
dim(training)
modFit <- train(classe ~ ., data=training, method= "rf", trainControl = tc, prox = TRUE)
?train
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE, allowParallel = TRUE)
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE, ntree = 10, allowParallel = TRUE)
modFit <- train(classe ~ ., data = training, method = "rf", trControl = tc, prox = TRUE, allowParallel = TRUE)
